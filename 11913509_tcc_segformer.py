# -*- coding: utf-8 -*-
"""11913509_TCC_SegFormer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N87uzmMeHacM74vc-tErczS0KM37uNcz

**Gabriela Sandanieli de Aguiar (11913509) - Engenharia de Computa√ß√£o - USP S√£o Carlos**

# **SegFormer**
"""

# Monta o Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Imports
import os
import numpy as np
from PIL import Image
from collections import Counter
import torch
from torch.utils.data import Dataset, DataLoader, Subset
from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation, Trainer, TrainingArguments, TrainerCallback
from sklearn.model_selection import StratifiedKFold, train_test_split
import torch.nn.functional as F
from tqdm import tqdm
import seaborn as sns
from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, precision_score, recall_score, f1_score, jaccard_score, ConfusionMatrixDisplay
import pandas as pd
import matplotlib.pyplot as plt

# Verifica GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Usando dispositivo: {device}")

# Fun√ß√£o para carregar as imagens
def load_dataset(base_dir):
    X, Y = [], []
    for sub in sorted(os.listdir(base_dir)):
        flair_dir = os.path.join(base_dir, sub, "flair")
        mask_dir = os.path.join(base_dir, sub, "mask")
        for flair_file in sorted(os.listdir(flair_dir)):
            flair_path = os.path.join(flair_dir, flair_file)
            flair_img = Image.open(flair_path).convert("L")
            flair_rgb = np.stack([np.array(flair_img)] * 3, axis=-1)
            X.append(Image.fromarray(flair_rgb))

            mask_path = os.path.join(mask_dir, flair_file.replace("slice", "mask"))
            if os.path.exists(mask_path):
                mask = Image.open(mask_path).convert("L")
                Y.append(Image.fromarray((np.array(mask) > 127).astype(np.uint8)))
            else:
                Y.append(Image.fromarray(np.zeros((256, 256), dtype=np.uint8)))
    return X, Y

# Carrega o dataset
base_dir = "/content/drive/MyDrive/TCC/slices_subs"
# X_all, Y_all = load_dataset(base_dir)

# Salva o dataset
# np.save("/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/X_tcc.npy", X_all)
# np.save("/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/Y_tcc.npy", Y_all)

# Carrega o dataset novamente
X_all = np.load("/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/X_tcc.npy")
Y_all = np.load("/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/Y_tcc.npy")

# Confirma o shape esperado
print("‚úÖ Dataset carregado:")
print("X:", X_all.shape)
print("Y:", Y_all.shape)

# Conta o n√∫mero de pixels com les√£o em cada imagem
lesion_pixel_counts = np.array([np.sum(y) for y in Y_all])

# Define n√≠veis de les√£o com base na quantidade de pixels
# 4 faixas para estratifica√ß√£o: 0 (sem les√£o), 1 (leve), 2 (m√©dia), 3 (alta)
lesion_levels = []
for count in lesion_pixel_counts:
    if count == 0:
        lesion_levels.append(0)
    elif count < 100:
        lesion_levels.append(1)
    elif count < 1000:
        lesion_levels.append(2)
    else:
        lesion_levels.append(3)
lesion_levels = np.array(lesion_levels)

print("\nDistribui√ß√£o das classes para estratifica√ß√£o (completa):")
print(Counter(lesion_levels))

# Separa dados para teste final (20% do total), com estratifica√ß√£o
X_trainval, X_test, Y_trainval, Y_test, levels_trainval, levels_test = train_test_split(
    X_all, Y_all, lesion_levels, test_size=0.2, stratify=lesion_levels, random_state=42
)

print("\nDistribui√ß√£o das classes para treino/valida√ß√£o:")
print(Counter(levels_trainval))

print("\nDistribui√ß√£o das classes para teste final:")
print(Counter(levels_test))

# Define os folds estratificados a partir do conjunto de treino/valida√ß√£o
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
folds = list(skf.split(X_trainval, levels_trainval))

# Mostra a distribui√ß√£o de classes em cada fold
for i, (_, val_idx) in enumerate(folds):
    val_classes = levels_trainval[val_idx]
    print(f"\nFold {i+1}")
    print(" - Valida√ß√£o - Distribui√ß√£o das classes:", dict(Counter(val_classes)))

# Dataset
class BrainSegDataset(Dataset):
    def __init__(self, images, masks, feature_extractor):
        self.images = images
        self.masks = masks
        self.feature_extractor = feature_extractor
    def __len__(self):
        return len(self.images)
    def __getitem__(self, idx):
        inputs = self.feature_extractor(images=self.images[idx], return_tensors="pt")
        inputs = {k: v.squeeze(0) for k, v in inputs.items()}
        inputs["labels"] = torch.tensor(np.array(self.masks[idx]), dtype=torch.int64)
        return inputs

# Feature extractor global
feature_extractor = SegformerFeatureExtractor(
    do_resize=True,
    size=512,
    do_normalize=True,
)

# M√©tricas
def dice_coef_torch(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.view(-1)
    y_pred_f = y_pred.view(-1)
    intersection = torch.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (torch.sum(y_true_f) + torch.sum(y_pred_f) + smooth)

def weighted_bce_torch(y_true, y_pred):
    weight = 50.0
    bce = F.binary_cross_entropy(y_pred, y_true, reduction='none')
    weight_vector = y_true * weight + (1. - y_true)
    return torch.mean(bce * weight_vector)

def combined_loss_torch(y_true, y_pred):
    return 0.5 * weighted_bce_torch(y_true, y_pred) + 0.5 * (1 - dice_coef_torch(y_true, y_pred))

def custom_loss(model, inputs):
    labels = inputs["labels"].float()
    outputs = model(**inputs)
    probs = torch.sigmoid(outputs.logits[:, 1:2, :, :])
    if probs.shape[-2:] != labels.shape[-2:]:
        probs = F.interpolate(probs, size=labels.shape[-2:], mode='bilinear', align_corners=False)
    loss = combined_loss_torch(labels.unsqueeze(1), probs)
    return loss, outputs

# Trainer customizado
class CustomTrainerWithDice(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        loss, outputs = custom_loss(model, inputs)
        return (loss, outputs) if return_outputs else loss

def evaluate_dice_epoch(model, dataset):
    model.eval()
    model = model.to(device)
    dices = []
    with torch.no_grad():
        for item in tqdm(dataset, desc="Avaliando Dice"):
            inputs = {k: v.unsqueeze(0).to(device) for k, v in item.items() if k != "labels"}
            labels = item["labels"].unsqueeze(0).to(device).float()
            outputs = model(**inputs)
            probs = torch.sigmoid(outputs.logits[:, 1:2, :, :])
            if probs.shape[-2:] != labels.shape[-2:]:
                probs = F.interpolate(probs, size=labels.shape[-2:], mode='bilinear', align_corners=False)
            preds_bin = (probs > 0.6).float()
            dice = dice_coef_torch(labels, preds_bin)
            dices.append(dice.item())
    model.train()
    return np.mean(dices)

# Fun√ß√£o auxiliar para calcular a m√©dia da loss em um dataset
def evaluate_loss_on_dataset(model, dataset, batch_size=8):
    model.eval()
    losses = []
    dataloader = DataLoader(dataset, batch_size=batch_size)
    with torch.no_grad():
        for batch in dataloader:
            batch = {k: v.to(model.device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
            loss, _ = custom_loss(model, batch)
            losses.append(loss.item())
    return np.mean(losses)

# Callback com Dice e Loss por √©poca
class DiceScoreCallback(TrainerCallback):
    def __init__(self):
        self.dice_train = []
        self.dice_val = []
        self.loss_train = []
        self.loss_val = []

    def on_epoch_end(self, args, state, control, **kwargs):
        model = self.trainer.model.to(self.trainer.args.device)

        # Dice
        dice_val = evaluate_dice_epoch(model, self.trainer.eval_dataset)
        dice_train = evaluate_dice_epoch(model, self.trainer.train_dataset)

        # Loss
        train_loss = evaluate_loss_on_dataset(model, self.trainer.train_dataset, batch_size=self.trainer.args.per_device_train_batch_size)
        val_loss = evaluate_loss_on_dataset(model, self.trainer.eval_dataset, batch_size=self.trainer.args.per_device_eval_batch_size)

        # Armazena
        self.dice_train.append(dice_train)
        self.dice_val.append(dice_val)
        self.loss_train.append(train_loss)
        self.loss_val.append(val_loss)

        print(f"Epoch {int(state.epoch)} ‚Äî Dice Treino: {dice_train:.4f} | Val: {dice_val:.4f} | Loss Treino: {train_loss:.4f} | Val: {val_loss:.4f}")

def dice_score_np(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

def safe_metrics(y_true, y_pred):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()

    if np.sum(y_true_f) == 0 and np.sum(y_pred_f) == 0:
        return {
            'dice': 1.0,
            'iou': 1.0,
            'recall': 1.0,
            'precision': 1.0,
            'f1': 1.0
        }

    return {
        'dice': dice_score_np(y_true, y_pred),
        'iou': jaccard_score(y_true_f, y_pred_f, zero_division=0),
        'recall': recall_score(y_true_f, y_pred_f, zero_division=0),
        'precision': precision_score(y_true_f, y_pred_f, zero_division=0),
        'f1': f1_score(y_true_f, y_pred_f, zero_division=0)
    }

# Lista para armazenar m√©tricas por fold
fold_metrics = []
histories = []

# Loop de folds
for fold, (train_idx, val_idx) in enumerate(folds):
    print(f"\nüîÅ Treinando Fold {fold+1}/{len(folds)}")

    # Subconjuntos
    X_train = [X_trainval[i] for i in train_idx]
    Y_train = [Y_trainval[i] for i in train_idx]
    X_val = [X_trainval[i] for i in val_idx]
    Y_val = [Y_trainval[i] for i in val_idx]

    train_dataset = BrainSegDataset(X_train, Y_train, feature_extractor)
    val_dataset = BrainSegDataset(X_val, Y_val, feature_extractor)

    # Modelo novo para cada fold
    model = SegformerForSemanticSegmentation.from_pretrained(
        "nvidia/segformer-b0-finetuned-ade-512-512",
        num_labels=2,
        ignore_mismatched_sizes=True,
        id2label={0: "background", 1: "lesion"},
        label2id={"background": 0, "lesion": 1}
    ).to(device)

    output_dir = f"/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/segformer_fold{fold+1}"
    training_args = TrainingArguments(
        output_dir=output_dir,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        num_train_epochs=30,
        eval_strategy="epoch",
        save_strategy="epoch",
        logging_strategy="epoch",
        logging_dir=f"{output_dir}/logs",
        report_to="none"
    )

    dice_callback = DiceScoreCallback()

    trainer = CustomTrainerWithDice(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        callbacks=[dice_callback]
    )

    dice_callback.trainer = trainer

    trainer.train()

    histories.append({
        'dice_coef': dice_callback.dice_train,
        'val_dice_coef': dice_callback.dice_val,
        'loss': dice_callback.loss_train,
        'val_loss': dice_callback.loss_val
    })

    # Avalia√ß√£o ap√≥s o treino
    model.eval()
    model = model.to(device)

    y_pred_bin = []
    y_probs = []
    with torch.no_grad():
        for item, original_mask in zip(val_dataset, Y_val):
            inputs = {k: v.unsqueeze(0).to(device) for k, v in item.items() if k != "labels"}
            logits = model(**inputs).logits
            probs = torch.sigmoid(logits[:, 1:2, :, :])

            h, w = original_mask.shape
            resized = torch.nn.functional.interpolate(
                probs, size=(h, w), mode='bilinear', align_corners=False
            )
            probs_np = resized.squeeze().cpu().numpy()
            y_probs.append(probs_np)

            preds = (resized > 0.6).float()
            preds_np = preds.squeeze().cpu().numpy()
            y_pred_bin.append(preds_np)

    # Converte listas para arrays
    y_pred_bin = np.array(y_pred_bin).astype(np.uint8)
    y_true_np = np.array([np.array(mask) for mask in Y_val])
    x_val_np = np.array([np.array(img) for img in X_val])

    # M√©tricas
    # Usa a fun√ß√£o segura
    metrics = safe_metrics(y_true_np, y_pred_bin)
    dice = metrics['dice']
    iou = metrics['iou']
    recall = metrics['recall']
    precision = metrics['precision']
    f1 = metrics['f1']

    print(f"‚úîÔ∏è Fold {fold+1} - Dice: {dice:.4f}, IoU: {iou:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}")

    # Armazena m√©tricas
    fold_metrics.append({
        'fold': fold + 1,
        'dice': dice,
        'iou': iou,
        'recall': recall,
        'precision': precision,
        'f1': f1
    })

    # Salva os arrays
    fold_dir = os.path.join(output_dir, f"fold_outputs/fold{fold+1}")
    os.makedirs(fold_dir, exist_ok=True)
    np.save(os.path.join(fold_dir, "X_val.npy"), x_val_np)
    np.save(os.path.join(fold_dir, "Y_val.npy"), y_true_np)
    np.save(os.path.join(fold_dir, "Y_pred.npy"), y_pred_bin)
    np.save(os.path.join(fold_dir, "Y_probs.npy"), np.array(y_probs))

    # Salva o hist√≥rico Dice por √©poca
    df_dice = pd.DataFrame({
        'epoch': list(range(1, len(dice_callback.dice_val) + 1)),
        'dice_train': dice_callback.dice_train,
        'dice_val': dice_callback.dice_val,
        'loss_train': dice_callback.loss_train,
        'loss_val': dice_callback.loss_val
    })
    df_dice.to_csv(os.path.join(fold_dir, "dice_history.csv"), index=False)

    # Salva o modelo e extractor
    trainer.save_model(output_dir)
    feature_extractor.save_pretrained(output_dir)

# Ao final de todos os folds, salva o CSV geral
df_metrics = pd.DataFrame(fold_metrics)
df_metrics.to_csv("/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/metricas_por_fold.csv", index=False)
print("\nTodas as m√©tricas salvas com sucesso!")

"""# **Gr√°ficos SegFormer**"""

# Visualiza√ß√£o de 20 slices
fold_num = 1
base_path = f"/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/segformer_fold{fold_num}/fold_outputs/fold{fold_num}"

# Carrega os arquivos
X_val = np.load(f"{base_path}/X_val.npy")
Y_val = np.load(f"{base_path}/Y_val.npy")
Y_pred = np.load(f"{base_path}/Y_pred.npy")

# Visualiza 20 slices
for i in range(20):
    plt.figure(figsize=(12, 4))

    # Imagem FLAIR (grayscale ou RGB)
    plt.subplot(1, 3, 1)
    plt.title("Imagem FLAIR")

    img = X_val[i]

    # Converte para escala de cinza se for RGB
    if img.ndim == 3 and img.shape[2] == 3:
        # converte RGB para cinza (usando pondera√ß√£o padr√£o)
        img_gray = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])
    else:
        img_gray = img.squeeze()

    plt.imshow(img_gray, cmap='viridis')
    plt.axis("off")

    # M√°scara Real
    plt.subplot(1, 3, 2)
    plt.title("M√°scara Real")
    plt.imshow(Y_val[i], cmap='viridis')
    plt.axis("off")

    # M√°scara Predita
    plt.subplot(1, 3, 3)
    plt.title("Predi√ß√£o SegFormer")
    plt.imshow(Y_pred[i], cmap='viridis')
    plt.axis("off")

    plt.tight_layout()
    plt.show()

def calculate_all_metrics(y_true, y_pred):
      y_true_f = y_true.flatten()
      y_pred_f = y_pred.flatten()

      # Caso sem les√£o e sem predi√ß√£o ‚Äî acerto completo
      if np.sum(y_true_f) == 0 and np.sum(y_pred_f) == 0:
          cm = np.array([[np.prod(y_true.shape), 0], [0, 0]])  # matriz com s√≥ TN
          return cm, 1.0, 1.0, 1.0, 1.0, 1.0

      cm = confusion_matrix(y_true_f, y_pred_f, labels=[0, 1])
      precision = precision_score(y_true_f, y_pred_f, zero_division=0)
      recall = recall_score(y_true_f, y_pred_f, zero_division=0)
      f1 = f1_score(y_true_f, y_pred_f, zero_division=0)
      iou = jaccard_score(y_true_f, y_pred_f, zero_division=0)
      dice = dice_score_np(y_true, y_pred)
      return cm, dice, iou, recall, precision, f1

# Fun√ß√£o de an√°lise qualitativa para SegFormer
def analyze_saved_fold_segformer(fold_dir, fold_number):
    # Carrega os dados
    X_val = np.load(os.path.join(fold_dir, "X_val.npy"))
    Y_val = np.load(os.path.join(fold_dir, "Y_val.npy"))
    Y_pred = np.load(os.path.join(fold_dir, "Y_pred.npy"))

    print(f"\nüîç An√°lise qualitativa - SegFormer - Fold {fold_number}")

    def plot_case(idx, title_extra=''):
        img = X_val[idx]
        if img.ndim == 3 and img.shape[2] == 3:
            # Converte RGB para escala de cinza para aplicar cmap
            flair = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])
        else:
            flair = img.squeeze()

        mask_true = Y_val[idx].squeeze()
        pred_bin = Y_pred[idx].squeeze()

        cm, dice, iou, recall, precision, f1 = calculate_all_metrics(mask_true, pred_bin)

        plt.figure(figsize=(15, 4))
        plt.subplot(1, 4, 1)
        plt.title("FLAIR (viridis)")
        plt.imshow(flair, cmap='viridis')
        plt.axis('off')

        plt.subplot(1, 4, 2)
        plt.title("M√°scara Real")
        plt.imshow(mask_true, cmap='viridis')
        plt.axis('off')

        plt.subplot(1, 4, 3)
        plt.title(f"Predi√ß√£o\nDice: {dice:.4f}")
        plt.imshow(pred_bin, cmap='viridis')
        plt.axis('off')

        plt.subplot(1, 4, 4)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', xticklabels=['Fundo', 'Les√£o'], yticklabels=['Fundo', 'Les√£o'])
        plt.title(f"Matriz de Confus√£o\n{title_extra}")
        plt.xlabel("Predito")
        plt.ylabel("Real")

        plt.tight_layout()
        plt.show()

        print(f"Dice: {dice:.4f}, IoU: {iou:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}")

    # Calcula informa√ß√µes por slice
    lesion_pixels_per_slice = np.array([np.sum(mask > 0) for mask in Y_val])
    dice_per_slice = np.array([dice_score_np(Y_val[i], Y_pred[i]) for i in range(len(Y_val))])

    # Caso 1: Sem les√£o e predi√ß√£o correta
    no_lesion_cases = np.where(lesion_pixels_per_slice == 0)[0]
    valid_no_lesion = [i for i in no_lesion_cases if np.sum(Y_pred[i]) == 0]
    if valid_no_lesion:
        plot_case(valid_no_lesion[0], title_extra="Sem Les√£o - Predi√ß√£o Correta")

    # Caso 2: Les√£o pequena
    lesion_small = np.where((lesion_pixels_per_slice > 100) & (lesion_pixels_per_slice < 400))[0]
    if len(lesion_small) > 0:
        plot_case(lesion_small[0], title_extra="Les√£o Pequena")

    # Caso 3: Maior les√£o
    plot_case(np.argmax(lesion_pixels_per_slice), title_extra="Maior Les√£o")

    # Caso 4: Maior Dice entre casos com les√£o
    cases_with_lesion = np.where(lesion_pixels_per_slice > 0)[0]
    if len(cases_with_lesion) > 0:
        idx_best_dice = cases_with_lesion[np.argmax(dice_per_slice[cases_with_lesion])]
        plot_case(idx_best_dice, title_extra="Maior Dice com Les√£o")

for i in range(1, 6):
    fold_path = f"/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/segformer_fold{i}/fold_outputs/fold{i}"
    analyze_saved_fold_segformer(fold_path, i)

# Plot Scatter
for fold in range(1, 6):
    path = f"/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/segformer_fold{fold}/fold_outputs/fold{fold}"
    Y_val = np.load(f"{path}/Y_val.npy")
    Y_pred = np.load(f"{path}/Y_pred.npy")

    lesion_sizes = []
    dice_scores = []

    for i in range(len(Y_val)):
        true_mask = Y_val[i].squeeze()
        pred_mask = Y_pred[i].squeeze()
        lesion_size = np.sum(true_mask > 0)
        dice = dice_score_np(true_mask, pred_mask)
        if lesion_size > 0:
            lesion_sizes.append(lesion_size)
            dice_scores.append(dice)

    # Scatter plot por fold
    plt.figure(figsize=(7, 5))
    plt.scatter(lesion_sizes, dice_scores, alpha=0.6, color='tab:purple')
    plt.title(f"SegFormer - Fold {fold} | Dice vs Tamanho da Les√£o")
    plt.xlabel("Tamanho da Les√£o (pixels)")
    plt.ylabel("Dice Score")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Curva ROC e Precision-Recall
for fold in range(1, 6):
    print(f"\nFold {fold}:")

    # Carrega os dados
    path = f"/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/segformer_fold{fold}/fold_outputs/fold{fold}"
    Y_val = np.load(f"{path}/Y_val.npy").flatten()
    Y_probs = np.load(f"{path}/Y_pred.npy").flatten()

    # ROC Curve
    fpr, tpr, _ = roc_curve(Y_val, Y_probs)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 5))
    plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc:.4f}', color='tab:purple')
    plt.plot([0, 1], [0, 1], 'k--', label='Aleat√≥rio')
    plt.title(f'Curva ROC - Fold {fold} (por pixel)')
    plt.xlabel('FPR')
    plt.ylabel('TPR')
    plt.legend()
    plt.grid()
    plt.show()

    # Precision-Recall Curve
    precision, recall, _ = precision_recall_curve(Y_val, Y_probs)
    pr_auc = auc(recall, precision)

    plt.figure(figsize=(8, 5))
    plt.plot(recall, precision, label=f'PR AUC = {pr_auc:.4f}', color='tab:purple')
    plt.title(f'Curva Precision-Recall - Fold {fold} (por pixel)')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.legend()
    plt.grid()
    plt.show()

    print(f"‚úîÔ∏è AUC ROC: {roc_auc:.4f} | AUC PR: {pr_auc:.4f}")

# Plot qualitativo com mapa de erro
def plot_case_qualitativo_segformer(x, y_true, y_pred_bin, idx, title_extra=''):
    img = x[idx]
    mask_true = y_true[idx].squeeze()
    pred_bin = y_pred_bin[idx].squeeze()

    # Converte para escala de cinza se for RGB
    if img.ndim == 3 and img.shape[2] == 3:
        flair = np.dot(img[..., :3], [0.2989, 0.5870, 0.1140])
    else:
        flair = img.squeeze()

    # M√©tricas
    cm, dice, iou, recall, precision, f1 = calculate_all_metrics(mask_true, pred_bin)

    # Mapa de erro colorido
    intersection = np.logical_and(mask_true == 1, pred_bin == 1)
    false_positive = np.logical_and(mask_true == 0, pred_bin == 1)
    false_negative = np.logical_and(mask_true == 1, pred_bin == 0)
    error_map = np.zeros((*mask_true.shape, 3), dtype=np.uint8)
    error_map[intersection] = [0, 255, 0]      # Verde = acerto
    error_map[false_positive] = [255, 0, 0]    # Vermelho = falso positivo
    error_map[false_negative] = [0, 0, 255]    # Azul = falso negativo

    # Plots
    plt.figure(figsize=(18, 5))
    plt.subplot(1, 4, 1)
    plt.title("FLAIR (viridis)")
    plt.imshow(flair, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 4, 2)
    plt.title(f"M√°scara Real\nPixels: {np.sum(mask_true)}")
    plt.imshow(mask_true, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 4, 3)
    plt.title(f"Predi√ß√£o\nDice: {dice:.4f}\nIoU: {iou:.4f}")
    plt.imshow(pred_bin, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 4, 4)
    plt.title("Mapa de Erro\nVerde: TP | Vermelho: FP | Azul: FN")
    plt.imshow(error_map)
    plt.axis('off')

    plt.suptitle(title_extra, fontsize=16)
    plt.tight_layout()
    plt.show()

    print(f"Dice: {dice:.4f}, IoU: {iou:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}")

# Loop por fold
for fold in range(1, 6):
    print(f"\nüîç SegFormer - Fold {fold}")

    path = f"/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/segformer_fold{fold}/fold_outputs/fold{fold}"
    X_val = np.load(os.path.join(path, "X_val.npy"))
    Y_val = np.load(os.path.join(path, "Y_val.npy"))
    Y_pred = np.load(os.path.join(path, "Y_pred.npy"))

    lesion_pixels = np.array([np.sum(y) for y in Y_val])
    dice_scores = np.array([
        dice_score_np(Y_val[i].squeeze(), Y_pred[i].squeeze())
        for i in range(len(Y_val))
    ])

    # Caso 1 ‚Äì Sem les√£o e fundo predito corretamente
    no_lesion = np.where(lesion_pixels == 0)[0]
    correct_bg = [i for i in no_lesion if np.sum(Y_pred[i]) == 0]
    if correct_bg:
        plot_case_qualitativo_segformer(X_val, Y_val, Y_pred, correct_bg[0], title_extra=f'Fold {fold}: Sem Les√£o')

    # Caso 2 ‚Äì Les√£o pequena
    small_lesion = np.where((lesion_pixels > 100) & (lesion_pixels < 400))[0]
    if len(small_lesion) > 0:
        plot_case_qualitativo_segformer(X_val, Y_val, Y_pred, small_lesion[0], title_extra=f'Fold {fold}: Les√£o Pequena')

    # Caso 3 ‚Äì Maior les√£o
    largest_idx = np.argmax(lesion_pixels)
    plot_case_qualitativo_segformer(X_val, Y_val, Y_pred, largest_idx, title_extra=f'Fold {fold}: Maior Les√£o')

    # Caso 4 ‚Äì Melhor Dice em slice com les√£o
    with_lesion = np.where(lesion_pixels > 0)[0]
    if len(with_lesion) > 0:
        best_dice_idx = with_lesion[np.argmax(dice_scores[with_lesion])]
        plot_case_qualitativo_segformer(X_val, Y_val, Y_pred, best_dice_idx, title_extra=f'Fold {fold}: Maior Dice')

# Matriz de confus√£o (por slice)
threshold = 0.6

for fold in range(1, 6):
    print(f"\nüîç SegFormer - Fold {fold}")
    fold_path = f"/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/segformer_fold{fold}/fold_outputs/fold{fold}"

    Y_val = np.load(f"{fold_path}/Y_val.npy")
    Y_pred = np.load(f"{fold_path}/Y_pred.npy")

    y_true_slice = []
    y_pred_slice = []

    for i in range(len(Y_val)):
        mask_true = Y_val[i].squeeze()
        mask_pred = Y_pred[i].squeeze()

        has_lesion_gt = int(np.sum(mask_true) > 0)
        has_lesion_pred = int(np.sum(mask_pred) > 0)

        y_true_slice.append(has_lesion_gt)
        y_pred_slice.append(has_lesion_pred)

    # Matriz de Confus√£o (presen√ßa de les√£o por slice)
    cm_slice = confusion_matrix(y_true_slice, y_pred_slice, labels=[0, 1])

    disp = ConfusionMatrixDisplay(confusion_matrix=cm_slice, display_labels=["Fundo", "Les√£o"])
    disp.plot(cmap='Purples', values_format='d')
    plt.title(f"Matriz de Confus√£o (por Slice) - Fold {fold}")
    plt.grid(False)
    plt.show()

# Matriz de confus√£o normalizada
threshold = 0.6
use_probs = False

for fold in range(1, 6):
    print(f"\nüîç SegFormer - Fold {fold}")
    fold_path = f"/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/segformer_fold{fold}/fold_outputs/fold{fold}"

    # Carrega
    Y_val = np.load(f"{fold_path}/Y_val.npy")

    if use_probs:
        Y_raw = np.load(f"{fold_path}/Y_probs.npy")  # cont√≠nuo
        Y_pred_bin = (Y_raw > threshold).astype(np.uint8)
    else:
        Y_pred_bin = np.load(f"{fold_path}/Y_pred.npy")  # j√° bin√°rio

    # Flatten de todas as slices
    all_y_true = Y_val.flatten()
    all_y_pred = Y_pred_bin.flatten()

    # Matriz de confus√£o
    cm_pixel = confusion_matrix(all_y_true, all_y_pred, labels=[0, 1])

    # Normaliza por linha
    cm_norm = cm_pixel.astype('float') / cm_pixel.sum(axis=1, keepdims=True)

    # Plot
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm_norm, annot=True, cmap='Purples', fmt='.2f',
                xticklabels=['Fundo', 'Les√£o'], yticklabels=['Fundo', 'Les√£o'])
    plt.title(f"Matriz de Confus√£o Normalizada (Pixel) - Fold {fold}" + (f" | Threshold {threshold}" if use_probs else ""))
    plt.xlabel("Predito")
    plt.ylabel("Real")
    plt.tight_layout()
    plt.show()

# Gr√°ficos de dice e loss
for fold, hist in enumerate(histories):
    epochs = np.arange(1, len(hist['loss']) + 1)
    mark_epochs = np.array([1] + list(range(5, len(hist['loss']) + 1, 5)))

    # Dice
    plt.figure(figsize=(8, 4))
    plt.plot(epochs, hist['dice_coef'], label='Dice Treino', color='tab:purple', marker='o', markevery=mark_epochs - 1)
    plt.plot(epochs, hist['val_dice_coef'], label='Dice Valida√ß√£o', color='tab:green', marker='s', markevery=mark_epochs - 1)
    plt.title(f'Fold {fold+1} - Curva de Dice (SegFormer)')
    plt.xlabel('√âpoca')
    plt.ylabel('Dice')
    plt.legend()
    plt.grid()
    plt.tight_layout()
    plt.show()

    # Loss
    plt.figure(figsize=(8, 4))
    plt.plot(epochs, hist['loss'], label='Loss Treino', color='tab:purple', marker='o', markevery=mark_epochs - 1)
    plt.plot(epochs, hist['val_loss'], label='Loss Valida√ß√£o', color='tab:green', marker='s', markevery=mark_epochs - 1)
    plt.title(f'Fold {fold+1} - Curva de Loss (SegFormer)')
    plt.xlabel('√âpoca')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid()
    plt.tight_layout()
    plt.show()

# Gr√°ficos dice e loss com desvio padr√£o
# Define o n√∫mero m√°ximo de √©pocas comuns entre os folds (para alinhar as curvas)
max_epochs = min(len(h['loss']) for h in histories)

# Extrai e corta os dados at√© o n√∫mero de √©pocas m√≠nimas
loss_train = np.array([h['loss'][:max_epochs] for h in histories])
loss_val = np.array([h['val_loss'][:max_epochs] for h in histories])
dice_train = np.array([h['dice_coef'][:max_epochs] for h in histories])
dice_val = np.array([h['val_dice_coef'][:max_epochs] for h in histories])

# Vetor de √©pocas
epochs = np.arange(1, max_epochs + 1)

# Curva de Loss com desvio padr√£o
plt.figure(figsize=(8, 5))
plt.plot(epochs, loss_train.mean(axis=0), label='Loss Treino (m√©dia)', color='tab:purple')
plt.fill_between(epochs,
                 loss_train.mean(axis=0) - loss_train.std(axis=0),
                 loss_train.mean(axis=0) + loss_train.std(axis=0),
                 alpha=0.2, color='tab:purple')

plt.plot(epochs, loss_val.mean(axis=0), label='Loss Valida√ß√£o (m√©dia)', color='tab:green')
plt.fill_between(epochs,
                 loss_val.mean(axis=0) - loss_val.std(axis=0),
                 loss_val.mean(axis=0) + loss_val.std(axis=0),
                 alpha=0.2, color='tab:green')

plt.title("Curva de Loss M√©dia com Desvio Padr√£o")
plt.xlabel("√âpocas")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Curva de Dice com desvio padr√£o
plt.figure(figsize=(8, 5))
plt.plot(epochs, dice_train.mean(axis=0), label='Dice Treino (m√©dia)', color='tab:purple')
plt.fill_between(epochs,
                 dice_train.mean(axis=0) - dice_train.std(axis=0),
                 dice_train.mean(axis=0) + dice_train.std(axis=0),
                 alpha=0.2, color='tab:purple')

plt.plot(epochs, dice_val.mean(axis=0), label='Dice Valida√ß√£o (m√©dia)', color='tab:green')
plt.fill_between(epochs,
                 dice_val.mean(axis=0) - dice_val.std(axis=0),
                 dice_val.mean(axis=0) + dice_val.std(axis=0),
                 alpha=0.2, color='tab:green')

plt.title("Curva de Dice M√©dia com Desvio Padr√£o")
plt.xlabel("√âpocas")
plt.ylabel("Dice")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""# **Teste final**"""

# Avalia√ß√£o no conjunto final de teste
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Prepara datasets
train_dataset = BrainSegDataset(X_trainval, Y_trainval, SegformerFeatureExtractor(do_resize=True, size=512, do_normalize=True))

# Usa s√≥ 5% do treino como "dummy validation"
eval_subset = Subset(train_dataset, indices=np.random.choice(len(train_dataset), size=int(0.05 * len(train_dataset)), replace=False))

# Modelo
model = SegformerForSemanticSegmentation.from_pretrained(
    "nvidia/segformer-b0-finetuned-ade-512-512",
    num_labels=2,
    ignore_mismatched_sizes=True,
    id2label={0: "background", 1: "lesion"},
    label2id={"background": 0, "lesion": 1}
).to(device)

# Treinamento final
final_model_dir = "/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/segformer_final_model"
training_args = TrainingArguments(
        output_dir=final_model_dir,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        num_train_epochs=30,
        save_strategy="epoch",
        eval_strategy="epoch",
        logging_strategy="epoch",
        logging_dir=f"{final_model_dir}/logs",
        report_to="none"
    )

dice_callback = DiceScoreCallback()

trainer = CustomTrainerWithDice(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_subset,
    callbacks=[dice_callback]
)

dice_callback.trainer = trainer

print("üöÄ Treinando modelo final no conjunto de treino/valida√ß√£o...")
trainer.train()

# Salva o modelo
trainer.save_model(final_model_dir)
SegformerFeatureExtractor(do_resize=True, size=512, do_normalize=True).save_pretrained(final_model_dir)

# Avalia√ß√£o no conjunto de teste
print("\n‚úÖ Avaliando no conjunto de teste...")
model.eval()

feature_extractor = SegformerFeatureExtractor.from_pretrained(final_model_dir)

y_probs, y_preds = [], []

with torch.no_grad():
    for x, y in tqdm(zip(X_test, Y_test), total=len(X_test)):
        inputs = feature_extractor(images=x, return_tensors="pt").to(device)
        logits = model(**inputs).logits
        probs = torch.sigmoid(logits[:, 1:2])
        h, w = y.shape
        probs_resized = torch.nn.functional.interpolate(probs, size=(h, w), mode='bilinear', align_corners=False)
        probs_np = probs_resized.squeeze().cpu().numpy()
        preds_np = (probs_np > 0.6).astype(np.uint8)

        y_probs.append(probs_np)
        y_preds.append(preds_np)

# Avalia√ß√£o
Y_test_np = np.array([np.array(y) for y in Y_test])
Y_pred_test = np.array(y_preds).astype(np.uint8)

metrics = safe_metrics(Y_test_np, Y_pred_test)
dice = metrics['dice']
iou = metrics['iou']
recall = metrics['recall']
precision = metrics['precision']
f1 = metrics['f1']

# Salva os arrays
out_path = "/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/final_test_outputs"
os.makedirs(out_path, exist_ok=True)
np.save(f"{out_path}/X_test.npy", np.array([np.array(x) for x in X_test]))
np.save(f"{out_path}/Y_test.npy", Y_test_np)
np.save(f"{out_path}/Y_pred_test.npy", Y_pred_test)
np.save(f"{out_path}/Y_probs_test.npy", np.array(y_probs))

print(f"\nüìä Teste Final ‚Äî Dice: {dice:.4f}, IoU: {iou:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}")

# Tabela resumo m√©tricas
csv_path = "/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/metricas_por_fold.csv"
df_folds = pd.read_csv(csv_path)

dice = metrics['dice']
iou = metrics['iou']
recall = metrics['recall']
precision = metrics['precision']
f1 = metrics['f1']

# Cria DataFrame com as m√©tricas do teste final j√° calculadas
df_test = pd.DataFrame([{
    'fold': 'Teste Final',
    'dice': dice,
    'iou': iou,
    'recall': recall,
    'precision': precision,
    'f1': f1
}])

# Calcula a m√©dia apenas dos folds
df_folds_only = df_folds[~df_folds['fold'].astype(str).str.lower().str.contains("teste")]
media_row = df_folds_only.mean(numeric_only=True)
media_row['fold'] = 'M√©dia (Folds)'

# Junta tudo em um DataFrame final
df_final = pd.concat([df_folds_only, pd.DataFrame([media_row]), df_test], ignore_index=True)
print("üîç Tabela Final com Folds, M√©dia e Teste Final:")
display(df_final.round(4))

# Visualiza√ß√£o de 20 slices de teste
Y_probs_test = np.load("/content/drive/MyDrive/TCC/ResultadosSegFormerFinal/final_test_outputs/Y_probs_test.npy")

# Garante que Y_probs_test e X_test est√£o no formato certo
Y_pred_bin_test = (Y_probs_test > 0.6).astype(np.uint8)

# Visualiza as 20 primeiras amostras do teste
for i in range(20):
    plt.figure(figsize=(12, 4))

    # FLAIR
    plt.subplot(1, 3, 1)
    plt.title("FLAIR")
    flair_img = X_test[i]
    if flair_img.ndim == 3:
        flair_img = flair_img[..., 0]  # Pega um canal se estiver RGB
    plt.imshow(flair_img, cmap='viridis')
    plt.axis('off')

    # M√°scara real
    plt.subplot(1, 3, 2)
    plt.title("M√°scara Real")
    plt.imshow(Y_test[i].squeeze(), cmap='viridis')
    plt.axis('off')

    # Predi√ß√£o bin√°ria
    plt.subplot(1, 3, 3)
    plt.title("Predi√ß√£o Bin√°ria")
    plt.imshow(Y_pred_bin_test[i].squeeze(), cmap='viridis')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

# Gr√°ficos dice e loss
epochs = np.arange(1, len(dice_callback.loss_train) + 1)
loss_train = dice_callback.loss_train
dice_train = dice_callback.dice_train

# Loss
plt.figure(figsize=(8, 5))
plt.plot(epochs, loss_train, label='Loss Treino (Modelo Final)', color='tab:purple', marker='o')
plt.title('Curva de Loss (Modelo Final)')
plt.xlabel('√âpoca')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# Dice
plt.figure(figsize=(8, 5))
plt.plot(epochs, dice_train, label='Dice Treino (Modelo Final)', color='tab:green', marker='s')
plt.title('Curva de Dice (Modelo Final)')
plt.xlabel('√âpoca')
plt.ylabel('Dice')
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# Plot Scatter
def dice_score(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

# C√°lculo do Dice por slice e tamanho da les√£o
lesion_pixels_per_slice_test = [np.sum(y.squeeze()) for y in Y_test_np]
dice_per_slice_test = [
    dice_score(y.squeeze(), y_hat.squeeze())
    for y, y_hat in zip(Y_test_np, Y_pred_test)
]

# Remove slices sem les√£o para o gr√°fico
valid_indices = np.array(lesion_pixels_per_slice_test) > 0
x_vals = np.array(lesion_pixels_per_slice_test)[valid_indices]
y_vals = np.array(dice_per_slice_test)[valid_indices]

# Scatter Plot
plt.figure(figsize=(8,5))
plt.scatter(x_vals, y_vals, alpha=0.6, color='tab:purple')
plt.title("Teste Final: Dice Score vs Tamanho da Les√£o (pixels)")
plt.xlabel("Tamanho da Les√£o (pixels)")
plt.ylabel("Dice Score")
plt.grid(True)
plt.tight_layout()
plt.show()

# Curva Precision-Recall
all_y_true = Y_test_np.flatten()
all_y_probs = Y_probs_test.flatten()

# Calcula curva PR e √°rea
precision, recall, thresholds_pr = precision_recall_curve(all_y_true, all_y_probs)
pr_auc = auc(recall, precision)

# Plot PR
plt.figure(figsize=(8, 5))
plt.plot(recall, precision, label=f'PR AUC = {pr_auc:.4f}', color='tab:purple')
plt.title('Curva Precision-Recall - Teste Final (por pixel)')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Resultado
print(f"AUC PR (teste final): {pr_auc:.4f}")

# Matriz de confus√£o (por slice)
threshold = 0.6

# Slice-wise: presen√ßa ou aus√™ncia de les√£o
y_true_slice = []
y_pred_slice = []

for i in range(len(Y_test_np)):
    mask_true = Y_test_np[i].squeeze()
    mask_pred = (Y_probs_test[i].squeeze() > threshold).astype(np.uint8)

    has_lesion_gt = int(np.sum(mask_true) > 0)
    has_lesion_pred = int(np.sum(mask_pred) > 0)

    y_true_slice.append(has_lesion_gt)
    y_pred_slice.append(has_lesion_pred)

# Matriz de Confus√£o por Slice
cm_slice = confusion_matrix(y_true_slice, y_pred_slice, labels=[0, 1])
disp = ConfusionMatrixDisplay(confusion_matrix=cm_slice, display_labels=["Fundo", "Les√£o"])
disp.plot(cmap='Purples', values_format='d')
plt.title("Matriz de Confus√£o (por Slice) - Teste Final")
plt.grid(False)
plt.tight_layout()
plt.show()

# Matriz de confus√£o normalizada
all_y_true = Y_test_np.flatten()
all_y_pred_bin = (Y_probs_test.flatten() > 0.6).astype(np.uint8)

# Matriz de confus√£o por pixel
cm_pixel = confusion_matrix(all_y_true, all_y_pred_bin, labels=[0, 1])
cm_norm = cm_pixel.astype('float') / cm_pixel.sum(axis=1, keepdims=True)

# Plot usando seaborn
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, cmap='Purples', fmt='.2f',
            xticklabels=['Fundo', 'Les√£o'], yticklabels=['Fundo', 'Les√£o'])

plt.title("Matriz de Confus√£o Normalizada (Pixel) - Teste Final")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.tight_layout()
plt.show()

# Plot case qualitativo com mapa de erro
def plot_case_qualitativo_teste(idx, title_extra=''):
    mask_true = Y_test[idx].squeeze()
    flair = X_test[idx].squeeze()
    pred_probs = Y_probs_test[idx].squeeze()
    pred_bin = (pred_probs > 0.6).astype(np.uint8)

    # M√©tricas
    cm, dice, iou, recall, precision, f1 = calculate_all_metrics(mask_true, pred_bin)

    # Mapa de erro
    intersection = np.logical_and(mask_true == 1, pred_bin == 1)
    false_positive = np.logical_and(mask_true == 0, pred_bin == 1)
    false_negative = np.logical_and(mask_true == 1, pred_bin == 0)
    error_map = np.zeros((*mask_true.shape, 3), dtype=np.uint8)
    error_map[intersection] = [0, 255, 0]    # TP - Verde
    error_map[false_positive] = [255, 0, 0]  # FP - Vermelho
    error_map[false_negative] = [0, 0, 255]  # FN - Azul

    # Plots
    plt.figure(figsize=(18, 5))
    plt.subplot(1, 4, 1)
    plt.title("FLAIR")
    plt.imshow(flair, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 4, 2)
    plt.title(f"M√°scara Real\nPixels: {np.sum(mask_true)}")
    plt.imshow(mask_true, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 4, 3)
    plt.title(f"Predi√ß√£o\nDice: {dice:.4f}\nIoU: {iou:.4f}")
    plt.imshow(pred_bin, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 4, 4)
    plt.title("Mapa de Erro\nVerde: TP | Vermelho: FP | Azul: FN")
    plt.imshow(error_map)
    plt.axis('off')

    plt.suptitle(title_extra, fontsize=16)
    plt.tight_layout()
    plt.show()

    print(f"Dice: {dice:.4f}, IoU: {iou:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}")

# Sele√ß√£o de casos interessantes
lesion_pixels_test = np.array([np.sum(mask.squeeze()) for mask in Y_test])
dice_per_slice_test = np.array([
    dice_score(y.squeeze(), (yp.squeeze() > 0.6).astype(np.uint8))
    for y, yp in zip(Y_test, Y_probs_test)
])

# Caso sem les√£o e sem predi√ß√£o
no_lesion_cases = np.where(lesion_pixels_test == 0)[0]
valid_no_lesion = [i for i in no_lesion_cases if np.sum((Y_probs_test[i].squeeze() > 0.6)) == 0]
if valid_no_lesion:
    plot_case_qualitativo_teste(valid_no_lesion[0], title_extra='Sem Les√£o - Predi√ß√£o Correta')

# Les√£o pequena (exemplo: entre 100 e 400 pixels)
lesion_small_cases = np.where((lesion_pixels_test > 100) & (lesion_pixels_test < 400))[0]
if len(lesion_small_cases) > 0:
    plot_case_qualitativo_teste(lesion_small_cases[0], title_extra='Les√£o Pequena')

# Caso com maior les√£o
idx_max_lesion = np.argmax(lesion_pixels_test)
plot_case_qualitativo_teste(idx_max_lesion, title_extra='Maior Les√£o')

# Caso com maior Dice entre os que t√™m les√£o
cases_with_lesion = np.where(lesion_pixels_test > 0)[0]
idx_best_dice = cases_with_lesion[np.argmax(dice_per_slice_test[cases_with_lesion])]
plot_case_qualitativo_teste(idx_best_dice, title_extra='Maior Dice com Les√£o')

# Plot qualitativo com matriz de confus√£o
def plot_qualitativo_teste(idx, title_extra=''):
    mask_true = Y_test[idx].squeeze()
    flair = X_test[idx].squeeze()
    pred_probs = Y_probs_test[idx].squeeze()
    pred_bin = (pred_probs > 0.6).astype(np.uint8)

    # M√©tricas
    cm, dice, iou, recall, precision, f1 = calculate_all_metrics(mask_true, pred_bin)

    # Visualiza√ß√£o
    plt.figure(figsize=(15, 4))

    # FLAIR
    plt.subplot(1, 4, 1)
    plt.title("FLAIR")
    if flair.ndim == 3:
        flair = flair[..., 0]  # Pega o primeiro canal se RGB
    plt.imshow(flair, cmap='viridis')
    plt.axis('off')

    # M√°scara real
    plt.subplot(1, 4, 2)
    plt.title("M√°scara Real")
    plt.imshow(mask_true, cmap='viridis')
    plt.axis('off')

    # Predi√ß√£o
    plt.subplot(1, 4, 3)
    plt.title(f"Predi√ß√£o\nDice: {dice:.4f}")
    plt.imshow(pred_bin, cmap='viridis')
    plt.axis('off')

    # Matriz de confus√£o
    plt.subplot(1, 4, 4)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',
                xticklabels=['Fundo', 'Les√£o'],
                yticklabels=['Fundo', 'Les√£o'])
    plt.title(f"Matriz de Confus√£o\n{title_extra}")
    plt.xlabel("Predito")
    plt.ylabel("Real")

    plt.tight_layout()
    plt.show()

    # Imprime m√©tricas num√©ricas
    print(f"Dice: {dice:.4f}, IoU: {iou:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}")

# Seleciona casos interessantes
lesion_pixels_test = np.array([np.sum(mask.squeeze()) for mask in Y_test])
dice_per_slice_test = np.array([
    dice_score(y.squeeze(), (yp.squeeze() > 0.6).astype(np.uint8))
    for y, yp in zip(Y_test, Y_probs_test)
])

# Caso sem les√£o e sem predi√ß√£o
no_lesion_cases = np.where(lesion_pixels_test == 0)[0]
valid_no_lesion = [i for i in no_lesion_cases if np.sum((Y_probs_test[i].squeeze() > 0.6)) == 0]
if valid_no_lesion:
    plot_qualitativo_teste(valid_no_lesion[0], title_extra='Sem Les√£o - Predi√ß√£o Correta')

# Caso com les√£o pequena
lesion_small_cases = np.where((lesion_pixels_test > 100) & (lesion_pixels_test < 400))[0]
if len(lesion_small_cases) > 0:
    plot_qualitativo_teste(lesion_small_cases[0], title_extra='Les√£o Pequena')

# Maior les√£o
idx_max_lesion = np.argmax(lesion_pixels_test)
plot_qualitativo_teste(idx_max_lesion, title_extra='Maior Les√£o')

# Maior Dice com les√£o
cases_with_lesion = np.where(lesion_pixels_test > 0)[0]
idx_best_dice = cases_with_lesion[np.argmax(dice_per_slice_test[cases_with_lesion])]
plot_qualitativo_teste(idx_best_dice, title_extra='Maior Dice com Les√£o')